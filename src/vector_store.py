import chromadb
from sentence_transformers import SentenceTransformer
from PIL import Image
import os

# ================= æ¨¡å‹åŠ è½½åŒºåŸŸ =================
print("æ­£åœ¨åˆå§‹åŒ–è§†è§‰æ¨¡å‹ (CLIP)...")
# ğŸŸ¢ å›é€€åˆ°æœ€ç¨³å®šçš„ CLIP æ¨¡å‹
# è¿™ä¸ªæ¨¡å‹å…¼å®¹æ€§æœ€å¥½ï¼Œä¸éœ€è¦ trust_remote_codeï¼Œä¹Ÿä¸ä¼šæŠ¥é”™
model = SentenceTransformer('clip-ViT-B-32')
# ===============================================

class MathKnowledgeBase:
    def __init__(self):
        # æ•°æ®åº“è·¯å¾„
        # ğŸŸ¢ æˆ‘ä»¬æ”¹å›ç”¨ clip å‘½åçš„æ–‡ä»¶å¤¹ï¼Œæ–¹ä¾¿åŒºåˆ†
        self.db_path = "./chroma_db_clip" 
        self.client = chromadb.PersistentClient(path=self.db_path)
        
        # åˆ›å»ºé›†åˆ
        self.collection = self.client.get_or_create_collection(
            name="math_questions_visual",
            metadata={"hnsw:space": "cosine"}
        )

    def _get_image_embedding(self, image_path):
        """
        CLIP æ¨¡å‹éå¸¸ç®€å•ï¼Œç›´æ¥ä¼ å›¾ç‰‡å°±è¡Œï¼Œä¸éœ€è¦å‰ç¼€
        """
        try:
            img = Image.open(image_path)
            # CLIP åªè¦å›¾ç‰‡ï¼Œä¸è¦ä»»ä½•èŠ±é‡Œèƒ¡å“¨çš„å‰ç¼€
            embedding = model.encode(img)
            return embedding.tolist()
        except Exception as e:
            print(f"âŒ å‘é‡åŒ–å¤±è´¥: {e}")
            return None

    def add_question(self, text_content, image_path, tags="", source="User"):
        if not os.path.exists(image_path):
            return False

        # è®¡ç®—ç‰¹å¾
        visual_vector = self._get_image_embedding(image_path)
        
        if visual_vector:
            doc_id = str(self.collection.count() + 1)
            self.collection.add(
                documents=[text_content],
                embeddings=[visual_vector], 
                metadatas=[{
                    "source": source, 
                    "tags": tags, 
                    "image_path": image_path
                }],
                ids=[doc_id]
            )
            return True
        return False

    def search_similar_image(self, query_image_path, top_k=1):
        # æœç´¢
        query_vector = self._get_image_embedding(query_image_path)
        
        if query_vector:
            results = self.collection.query(
                query_embeddings=[query_vector], 
                n_results=top_k
            )
            return results
        return None